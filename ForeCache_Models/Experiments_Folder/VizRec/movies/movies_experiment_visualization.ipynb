{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T03:21:21.108179Z",
     "start_time": "2024-03-27T03:21:21.100919Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for task p1\n",
      "Processing for task p2\n",
      "Processing for task p3\n",
      "Processing for task p4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the tasks\n",
    "tasks = ['p1', 'p2', 'p3', 'p4']\n",
    "df_all_master= pd.DataFrame()\n",
    "# Loop over each task\n",
    "for task in tasks:\n",
    "    results_path = f'./{task}/'\n",
    "    algorithms = sorted(['Random', 'Greedy', 'SARSA', 'QLearn', 'Reinforce', 'ActorCritic', 'WSLS','HMM','Momentum','Ottley-HMM','Bayesian'])\n",
    "    print('Processing for task', task)\n",
    "\n",
    "    # Initialize an empty DataFrame to store results for the task\n",
    "    df_all = pd.DataFrame()\n",
    "    # Loop over each algorithm\n",
    "    for algo in algorithms:\n",
    "        try:\n",
    "            # Read the CSV file for the algorithm\n",
    "            df = pd.read_csv(results_path + algo + '.csv')\n",
    "            #openended or not column\n",
    "            if task in ['p1','p2']:\n",
    "                df['Openended'] = 'Focused'\n",
    "            else:\n",
    "                df['Openended'] = 'Openended'\n",
    "            # Add a 'task' column to the DataFrame\n",
    "            df['Task'] = task\n",
    "\n",
    "            # Add an 'Algorithm' column to the DataFrame\n",
    "            df['Algorithm'] = algo\n",
    "        except FileNotFoundError:\n",
    "            print('No file for', algo)\n",
    "            continue\n",
    "\n",
    "        # Concatenate the current DataFrame with the DataFrame for all algorithms\n",
    "        df_all = pd.concat([df_all, df])\n",
    "        dataset= 'Movies'\n",
    "        filename = f'all_experiments_{dataset}_{task}.csv'\n",
    "        df_all.to_csv(filename, index=False)\n",
    "        df_all_master = pd.concat([df_all_master, df_all])\n",
    "\n",
    "df_all_master.to_csv('all_experiments_Movies.csv', index=False)\n",
    "\n",
    "\n",
    "# # plot openended subste\n",
    "# plotter(df_all[df_all['Openended']=='Focused'],'Openended','birdstrikes')\n",
    "# # plot focused subset\n",
    "# plotter(df_all[df_all['Openended']=='Focused'],'Focused','birdstrikes')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T03:21:25.661063Z",
     "start_time": "2024-03-27T03:21:21.340197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "    Algorithm          User  Threshold  LearningRate  Discount  Temperature  \\\n0         HMM  pro13_ace_p1        0.1           0.0       0.0          NaN   \n1         HMM  pro13_ace_p1        0.2           0.0       0.0          NaN   \n2         HMM  pro13_ace_p1        0.3           0.0       0.0          NaN   \n3         HMM  pro13_ace_p1        0.4           0.0       0.0          NaN   \n4         HMM  pro13_ace_p1        0.5           0.0       0.0          NaN   \n..        ...           ...        ...           ...       ...          ...   \n319       HMM   stu7_ade_p4        0.5           0.0       0.0          NaN   \n320       HMM   stu7_ade_p4        0.6           0.0       0.0          NaN   \n321       HMM   stu7_ade_p4        0.7           0.0       0.0          NaN   \n322       HMM   stu7_ade_p4        0.8           0.0       0.0          NaN   \n323       HMM   stu7_ade_p4        0.9           0.0       0.0          NaN   \n\n     Accuracy StateAccuracy  Reward  Epsilon  Openended Task participant_id  \\\n0    0.826087           NaN     NaN      NaN    Focused   p1            NaN   \n1    0.800000           NaN     NaN      NaN    Focused   p1            NaN   \n2    0.888889           NaN     NaN      NaN    Focused   p1            NaN   \n3    1.000000           NaN     NaN      NaN    Focused   p1            NaN   \n4    1.000000           NaN     NaN      NaN    Focused   p1            NaN   \n..        ...           ...     ...      ...        ...  ...            ...   \n319  0.373333           NaN     NaN      NaN  Openended   p4            NaN   \n320  0.416667           NaN     NaN      NaN  Openended   p4            NaN   \n321  0.444444           NaN     NaN      NaN  Openended   p4            NaN   \n322  0.466667           NaN     NaN      NaN  Openended   p4            NaN   \n323  0.400000           NaN     NaN      NaN  Openended   p4            NaN   \n\n    user  threshold  ncp-1  rank  \n0    NaN        NaN    NaN   NaN  \n1    NaN        NaN    NaN   NaN  \n2    NaN        NaN    NaN   NaN  \n3    NaN        NaN    NaN   NaN  \n4    NaN        NaN    NaN   NaN  \n..   ...        ...    ...   ...  \n319  NaN        NaN    NaN   NaN  \n320  NaN        NaN    NaN   NaN  \n321  NaN        NaN    NaN   NaN  \n322  NaN        NaN    NaN   NaN  \n323  NaN        NaN    NaN   NaN  \n\n[10368 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>User</th>\n      <th>Threshold</th>\n      <th>LearningRate</th>\n      <th>Discount</th>\n      <th>Temperature</th>\n      <th>Accuracy</th>\n      <th>StateAccuracy</th>\n      <th>Reward</th>\n      <th>Epsilon</th>\n      <th>Openended</th>\n      <th>Task</th>\n      <th>participant_id</th>\n      <th>user</th>\n      <th>threshold</th>\n      <th>ncp-1</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HMM</td>\n      <td>pro13_ace_p1</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.826087</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Focused</td>\n      <td>p1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HMM</td>\n      <td>pro13_ace_p1</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.800000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Focused</td>\n      <td>p1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HMM</td>\n      <td>pro13_ace_p1</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.888889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Focused</td>\n      <td>p1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HMM</td>\n      <td>pro13_ace_p1</td>\n      <td>0.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Focused</td>\n      <td>p1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HMM</td>\n      <td>pro13_ace_p1</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Focused</td>\n      <td>p1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>319</th>\n      <td>HMM</td>\n      <td>stu7_ade_p4</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.373333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Openended</td>\n      <td>p4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>320</th>\n      <td>HMM</td>\n      <td>stu7_ade_p4</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.416667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Openended</td>\n      <td>p4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>HMM</td>\n      <td>stu7_ade_p4</td>\n      <td>0.7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.444444</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Openended</td>\n      <td>p4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>322</th>\n      <td>HMM</td>\n      <td>stu7_ade_p4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.466667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Openended</td>\n      <td>p4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>HMM</td>\n      <td>stu7_ade_p4</td>\n      <td>0.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.400000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Openended</td>\n      <td>p4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>10368 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_master[df_all_master['Algorithm']=='HMM']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T03:21:25.686737Z",
     "start_time": "2024-03-27T03:21:25.676157Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#join 2 results dataframe for 2 dataset\n",
    "df_all_master_birdstrikes = pd.read_csv(\"../birdstrikes/all_experiments_BirdStrikes.csv\")\n",
    "df_all_master_movies = pd.read_csv(\"all_experiments_Movies.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T03:08:31.799899Z",
     "start_time": "2024-03-27T03:08:31.250235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#join these 2 datasets add a new column called dataset and put the name Movies or BirdStrikes\n",
    "df_all_master_birdstrikes['Dataset'] = 'BirdStrikes'\n",
    "df_all_master_movies['Dataset'] = 'Movies'\n",
    "#for column User keep only first four letters\n",
    "\n",
    "df_all_master_overall = pd.concat([df_all_master_birdstrikes,df_all_master_movies])\n",
    "df_all_master_overall['User'] = df_all_master_overall['User'].str[:5]\n",
    "df_all_master_overall.to_csv('all_experiments_overall.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T03:06:45.509502Z",
     "start_time": "2024-03-27T03:06:43.434041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "len(df_all_master_overall['User'].unique())\n",
    "#remove naive algorithm nad hmm\n",
    "df_all_master_overall = df_all_master_overall[~df_all_master_overall['Algorithm'].isin(['Naive','HMM'])]\n",
    "#for each algorithm give the number of users for whom the algo is wth the MaX AVERAGE ACCURACY\n",
    "df_users=df_all_master_overall.groupby(['User','Algorithm'])['Accuracy'].mean().reset_index().sort_values('Accuracy',ascending=False).groupby('User').head(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T02:53:17.425093Z",
     "start_time": "2024-03-27T02:53:17.308622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Algorithm\nQLearn         32\nSARSA          25\nActorCritic     8\nReinforce       7\nName: count, dtype: int64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users['Algorithm'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T02:53:17.427586Z",
     "start_time": "2024-03-27T02:53:17.424278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "QLearn         31\n",
      "SARSA          25\n",
      "ActorCritic     8\n",
      "Reinforce       7\n",
      "Bayesian        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the plotter function\n",
    "def plotter(ax, df_all, task, dataset):\n",
    "    # Define a color palette with the same colors for each algorithm\n",
    "    palette = sns.color_palette('husl', n_colors=len(algorithms))\n",
    "\n",
    "    # Group by 'Threshold' and 'Algorithm' and calculate the mean accuracy\n",
    "    df_avg = df_all.groupby(['Threshold', 'Algorithm'])['Accuracy'].mean().reset_index()\n",
    "\n",
    "    # Create the line plot with specified palette and markers\n",
    "    sns.lineplot(x=\"Threshold\", y=\"Accuracy\", hue=\"Algorithm\", data=df_avg, ax=ax,\n",
    "                 palette=palette, markers=True, style=\"Algorithm\")\n",
    "\n",
    "    # Plot the overall average line\n",
    "    df_avg_overall = df_avg.groupby(['Threshold'])['Accuracy'].mean().reset_index()\n",
    "    ax.plot(df_avg_overall['Threshold'], df_avg_overall['Accuracy'], label='Overall Average', color='black')\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title('Average Accuracy per Threshold for ' + task + ' task on ' + dataset + ' dataset')\n",
    "\n",
    "    # Remove legend\n",
    "    ax.legend().remove()\n",
    "\n",
    "# Define the tasks, results path, and algorithms\n",
    "tasks = ['p1', 'p2', 'p3', 'p4']\n",
    "algorithms = sorted(['Random', 'Greedy', 'SARSA', 'QLearn', 'Reinforce', 'ActorCritic', 'Naive', 'WSLS'])\n",
    "\n",
    "# Create a 2x2 grid of plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Initialize an empty list to collect legend handles and labels\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "# Loop over each task\n",
    "for i, task in enumerate(tasks):\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    # Loop over each algorithm\n",
    "    for algo in algorithms:\n",
    "        try:\n",
    "            # Read the CSV file for the algorithm\n",
    "            df = pd.read_csv(f'./{task}/{algo}.csv')\n",
    "            df['Algorithm'] = algo\n",
    "        except FileNotFoundError:\n",
    "            print('No file for', algo)\n",
    "            continue\n",
    "\n",
    "        # Concatenate the current DataFrame with the DataFrame for all algorithms\n",
    "        if algo == 'Random':\n",
    "            df_all = df\n",
    "        else:\n",
    "            df_all = pd.concat([df_all, df])\n",
    "\n",
    "    # Pass the current axes and data to the plotter function\n",
    "    plotter(axes[i], df_all, task, 'BirdStrikes')\n",
    "\n",
    "    # # Get legend handles and labels for the last chart\n",
    "    # if task == tasks[-1]:\n",
    "    #     handles, labels = axes[i].get_legend_handles_labels()\n",
    "    #     legend_handles.extend(handles)\n",
    "    #     legend_labels.extend(labels)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# # Add legend horizontally at the bottom for all algorithms\n",
    "# fig.legend(legend_handles, legend_labels, bbox_to_anchor=(0.5, -0.1), loc='upper center', ncol=len(algorithms))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T09:03:09.289879Z",
     "start_time": "2024-03-12T09:03:09.272089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T05:58:58.129077Z",
     "start_time": "2024-03-11T05:58:58.113980Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
